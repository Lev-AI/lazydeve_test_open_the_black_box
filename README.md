# ğŸ§  Enter The Black Box

A Machine Learning Robustness Lab for Evolving Cyber Attacks
(Stress-Testing ML Models for Cybersecurity Drift, Mutation & Resilience)

---

> âš™ï¸ *Note: This is a special test project created to demonstrate and test the capabilities of the LazyDeve agent, including synchronization, file management, and AI-assisted development.*

---

## â­ Overview
Enter The Black Box is a research ML platform designed to analyze the robustness of cybersecurity models against evolving attack patterns.
It shows:
- how traffic or log changes break ML models
- which features are critical
- how False Negatives / False Positives grow
- where the model becomes blind
- how it behaves under data drift, noise injection, and adversarial perturbations.

This is not just an IDS model â€” it's a lab that helps understand how fragile ML-based cybersecurity systems can be and how to improve them.

---

## ğŸ— Architecture
```
Enter-The-Black-Box/
â”‚
â”œâ”€â”€ data/                     # Datasets (CIC-IDS2017 / UNSW-NB15)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py        # Data loading and cleaning
â”‚   â”œâ”€â”€ baseline_model.py     # RandomForest/XGBoost baseline
â”‚   â”œâ”€â”€ mutation_engine.py    # Attack pattern mutation module
â”‚   â”œâ”€â”€ drift_detector.py     # Evidently + Alibi Detect
â”‚   â”œâ”€â”€ robustness_eval.py    # Baseline vs mutated comparison
â”‚   â”œâ”€â”€ explainability.py     # SHAP visualizations
â”‚   â”œâ”€â”€ report_generator.py   # Automatic reports
â”‚   â””â”€â”€ dashboard.py          # Streamlit dashboard
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_baseline.ipynb
â”‚   â”œâ”€â”€ 02_mutations.ipynb
â”‚   â”œâ”€â”€ 03_drift_tests.ipynb
â”‚   â””â”€â”€ 04_shap_analysis.ipynb
â”‚
â”œâ”€â”€ mlruns/                   # MLflow logs (auto-created)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ¯ Key Features
- Baseline ML IDS model (RandomForest/XGBoost)
- Attack Mutation Engine (drop features, add noise, create drift, mutate patterns)
- Data Drift Detection (Evidently AI, Alibi Detect)
- Concept Drift Detection
- Adversarial Sample Simulation
- Robustness Scoring & Metrics Comparison
- Explainability (SHAP)
- Interactive Streamlit Dashboard
- MLflow Experiment Tracking
- Clear reports for SOC / Threat Research teams

---

## ğŸ”¬ Why This Project Is Important
Modern IDS/NDR systems increasingly use ML â€” but very few test:
- how models behave under data drift
- if they detect slightly modified attacks
- what happens with corrupted logs
- which features are single points of failure
- where dangerous False Negatives appear

This project reveals weak points in ML-based security models.

---

## âš™ï¸ Core Components
### ğŸ”¥ 1. Attack Mutation Engine
Simulates attack pattern changes â€” feature removal, noise injection, frequency mutation, or adversarial tweaks.

### ğŸ“ˆ 2. Drift Detection Layer
Uses **Evidently AI** and **Alibi Detect** for drift and adversarial detection.

### ğŸ¤– 3. ML Baseline
Models: **RandomForest** or **XGBoost**, trained on **CIC-IDS2017** or **UNSW-NB15** datasets.

### ğŸ§  4. Explainability (SHAP)
Visualizes feature importance and explains model behavior.

### ğŸ“Š 5. Streamlit Dashboard
Interactive UI to run mutation scenarios and visualize results.

### ğŸ“œ 6. MLflow Logging
Tracks parameters, metrics, and experiment outcomes.

---

## ğŸš€ How It Works (Workflow)
1. Load dataset (CIC-IDS2017 / UNSW)
2. Train baseline model
3. Run mutation scenario
4. Re-evaluate model
5. Detect drift
6. Explain errors (SHAP)
7. Generate report
8. Visualize results with Streamlit

---

## ğŸ“Š Example Use Cases
- Test ML model robustness
- Evaluate IDS readiness for new attacks
- Analyze detection pipeline weaknesses
- Study adversarial attacks
- Build whitepapers or R&D reports

---

## ğŸ‘¤ For Who This Project Is
- SOC Analysts
- Threat Researchers
- Data Scientists
- Cybersecurity ML Engineers
- Students and Researchers
- Red Teamers
- Anyone studying ML + Cybersecurity

---

## ğŸ›  Requirements
```
python >= 3.10
scikit-learn
xgboost
pandas
numpy
evidently
alibi-detect
shap
matplotlib
plotly
streamlit
mlflow
```

---

## ğŸ“˜ Roadmap
**MVP (1â€“2 weeks)**
- baseline model
- mutation engine
- drift detection
- notebooks

**Phase 2**
- Streamlit dashboard
- MLflow integration

**Phase 3**
- synthetic attack generation
- adversarial ML
- GAN/VAE for attack synthesis

**Phase 4**
- real-time drift detector
- integration with Zeek logs
- integration with Suricata alerts

---

## ğŸ“„ License
MIT â€” free for education and research.

---

## âœ‰ï¸ Contact
Created by **Kapitan Lev âš“**  
AI-powered Cyber Analyst & ML Researcher