{
  "version": "1.0",
  "schema_version": "1.0",
  "project": "test_open_the_black_box",
  "last_sync": "2026-02-01T11:39:38.962274",
  "sync_status": "idle",
  "status": "active",
  "files_updated": 0,
  "files_reverted": [],
  "changed_files": [],
  "commits_cached": 0,
  "commits": [],
  "created_at": "2025-12-09T21:52:18.897583Z",
  "last_updated": "2025-12-09T21:52:18.897583Z",
  "metadata": {
    "readme_content": "# ğŸ§  Enter The Black Box\n\nA Machine Learning Robustness Lab for Evolving Cyber Attacks\n(Stress-Testing ML Models for Cybersecurity Drift, Mutation & Resilience)\n\n---\n\n> âš™ï¸ *Note: This is a special test project created to demonstrate and test the capabilities of the LazyDeve agent, including synchronization, file management, and AI-assisted development.*\n\n---\n\n## â­ Overview\nEnter The Black Box is a research ML platform designed to analyze the robustness of cybersecurity models against evolving attack patterns.\nIt shows:\n- how traffic or log changes break ML models\n- which features are critical\n- how False Negatives / False Positives grow\n- where the model becomes blind\n- how it behaves under data drift, noise injection, and adversarial perturbations.\n\nThis is not just an IDS model â€” it's a lab that helps understand how fragile ML-based cybersecurity systems can be and how to improve them.\n\n---\n\n## ğŸ— Architecture\n```\nEnter-The-Black-Box/\nâ”‚\nâ”œâ”€â”€ data/                     # Datasets (CIC-IDS2017 / UNSW-NB15)\nâ”‚\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ data_loader.py        # Data loading and cleaning\nâ”‚   â”œâ”€â”€ baseline_model.py     # RandomForest/XGBoost baseline\nâ”‚   â”œâ”€â”€ mutation_engine.py    # Attack pattern mutation module\nâ”‚   â”œâ”€â”€ drift_detector.py     # Evidently + Alibi Detect\nâ”‚   â”œâ”€â”€ robustness_eval.py    # Baseline vs mutated comparison\nâ”‚   â”œâ”€â”€ explainability.py     # SHAP visualizations\nâ”‚   â”œâ”€â”€ report_generator.py   # Automatic reports\nâ”‚   â””â”€â”€ dashboard.py          # Streamlit dashboard\nâ”‚\nâ”œâ”€â”€ notebooks/\nâ”‚   â”œâ”€â”€ 01_baseline.ipynb\nâ”‚   â”œâ”€â”€ 02_mutations.ipynb\nâ”‚   â”œâ”€â”€ 03_drift_tests.ipynb\nâ”‚   â””â”€â”€ 04_shap_analysis.ipynb\nâ”‚\nâ”œâ”€â”€ mlruns/                   # MLflow logs (auto-created)\nâ”‚\nâ”œâ”€â”€ README.md\nâ””â”€â”€ requirements.txt\n```\n\n---\n\n## ğŸ¯ Key Features\n- Baseline ML IDS model (RandomForest/XGBoost)\n- Attack Mutation Engine (drop features, add noise, create drift, mutate patterns)\n- Data Drift Detection (Evidently AI, Alibi Detect)\n- Concept Drift Detection\n- Adversarial Sample Simulation\n- Robustness Scoring & Metrics Comparison\n- Explainability (SHAP)\n- Interactive Streamlit Dashboard\n- MLflow Experiment Tracking\n- Clear reports for SOC / Threat Research teams\n\n---\n\n## ğŸ”¬ Why This Project Is Important\nModern IDS/NDR systems increasingly use ML â€” but very few test:\n- how models behave under data drift\n- if they detect slightly modified attacks\n- what happens with corrupted logs\n- which features are single points of failure\n- where dangerous False Negatives appear\n\nThis project reveals weak points in ML-based security models.\n\n---\n\n## âš™ï¸ Core Components\n### ğŸ”¥ 1. Attack Mutation Engine\nSimulates attack pattern changes â€” feature removal, noise injection, frequency mutation, or adversarial tweaks.\n\n### ğŸ“ˆ 2. Drift Detection Layer\nUses **Evidently AI** and **Alibi Detect** for drift and adversarial detection.\n\n### ğŸ¤– 3. ML Baseline\nModels: **RandomForest** or **XGBoost**, trained on **CIC-IDS2017** or **UNSW-NB15** datasets.\n\n### ğŸ§  4. Explainability (SHAP)\nVisualizes feature importance and explains model behavior.\n\n### ğŸ“Š 5. Streamlit Dashboard\nInteractive UI to run mutation scenarios and visualize results.\n\n### ğŸ“œ 6. MLflow Logging\nTracks parameters, metrics, and experiment outcomes.\n\n---\n\n## ğŸš€ How It Works (Workflow)\n1. Load dataset (CIC-IDS2017 / UNSW)\n2. Train baseline model\n3. Run mutation scenario\n4. Re-evaluate model\n5. Detect drift\n6. Explain errors (SHAP)\n7. Generate report\n8. Visualize results with Streamlit\n\n---\n\n## ğŸ“Š Example Use Cases\n- Test ML model robustness\n- Evaluate IDS readiness for new attacks\n- Analyze detection pipeline weaknesses\n- Study adversarial attacks\n- Build whitepapers or R&D reports\n\n---\n\n## ğŸ‘¤ For Who This Project Is\n- SOC Analysts\n- Threat Researchers\n- Data Scientists\n- Cybersecurity ML Engineers\n- Students and Researchers\n- Red Teamers\n- Anyone studying ML + Cybersecurity\n\n---\n\n## ğŸ›  Requirements\n```\npython >= 3.10\nscikit-learn\nxgboost\npandas\nnumpy\nevidently\nalibi-detect\nshap\nmatplotlib\nplotly\nstreamlit\nmlflow\n```\n\n---\n\n## ğŸ“˜ Roadmap\n**MVP (1â€“2 weeks)**\n- baseline model\n- mutation engine\n- drift detection\n- notebooks\n\n**Phase 2**\n- Streamlit dashboard\n- MLflow integration\n\n**Phase 3**\n- synthetic attack generation\n- adversarial ML\n- GAN/VAE for attack synthesis\n\n**Phase 4**\n- real-time drift detector\n- integration with Zeek logs\n- integration with Suricata alerts\n\n---\n\n## ğŸ“„ License\nMIT â€” free for education and research.\n\n---\n\n## âœ‰ï¸ Contact\nCreated by **Kapitan Lev âš“**  \nAI-powered Cyber Analyst & ML Researcher",
    "readme_checksum": "23b1d4df69b322c3c88b4cf94b76a2a1",
    "readme_loaded": true,
    "readme_last_updated": "2026-02-01T11:39:38.962274Z"
  }
}