{
  "version": "1.0",
  "schema_version": "1.0",
  "project": "test_open_the_black_box",
  "last_sync": "2025-12-09T21:52:18.932591",
  "sync_status": "idle",
  "status": "active",
  "files_updated": 0,
  "files_reverted": [],
  "changed_files": [],
  "commits_cached": 0,
  "commits": [],
  "created_at": "2025-12-09T21:52:18.897583Z",
  "last_updated": "2025-12-09T21:52:18.897583Z",
  "metadata": {
    "readme_content": "# ğŸ§  Enter The Black Box\n\nA Machine Learning Robustness Lab for Evolving Cyber Attacks\n(Stress-Testing ML Models for Cybersecurity Drift, Mutation & Resilience)\n\n---\n\n## ğŸš€ Overview\n**Enter The Black Box** is a modular research platform designed to analyze and improve the **robustness of ML-based cybersecurity models**. It enables testing how intrusion detection systems (IDS/NDR) behave under **data drift, adversarial noise, and feature corruption**.\n\n---\n\n## ğŸ§© Key Capabilities\n- **Baseline Training** â€” Train ML models (RandomForest, XGBoost) on IDS datasets like NSL-KDD.\n- **Attack Mutation Engine** â€” Simulate adversarial noise, drift, and missing features.\n- **Drift Detection** â€” Detect and visualize data drift using Evidently AI and Alibi Detect.\n- **Robustness Evaluation** â€” Measure performance degradation between baseline and mutated datasets.\n- **Explainability** â€” Understand feature importance and model behavior with SHAP.\n- **Visualization Tools** â€” Static (Matplotlib) and interactive (Streamlit) dashboards for analysis.\n- **Experiment Tracking** â€” Full MLflow integration for logging models, metrics, and reports.\n\n---\n\n## ğŸ— Project Structure\n```\nEnter-The-Black-Box/\nâ”‚\nâ”œâ”€â”€ data/                     # Datasets\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ data_loader.py        # Dataset loading and preprocessing\nâ”‚   â”œâ”€â”€ baseline_model.py     # Baseline model training and evaluation\nâ”‚   â”œâ”€â”€ mutation_engine.py    # Data mutation and drift simulation\nâ”‚   â”œâ”€â”€ drift_detector.py     # Evidently + Alibi drift detection\nâ”‚   â”œâ”€â”€ robustness_eval.py    # Compare baseline vs mutated results\nâ”‚   â”œâ”€â”€ explainability.py     # SHAP explainability\nâ”‚   â”œâ”€â”€ report_generator.py   # MLflow report generation\nâ”‚   â”œâ”€â”€ dashboard.py          # Streamlit dashboard\nâ”‚   â”œâ”€â”€ run_experiment.py     # Full automation pipeline\nâ”‚   â””â”€â”€ visualize_results.py  # Offline result visualization\nâ”‚\nâ”œâ”€â”€ notebooks/                # Jupyter notebooks for experiments\nâ”‚   â”œâ”€â”€ 01_baseline.ipynb\nâ”‚   â”œâ”€â”€ 02_mutations.ipynb\nâ”‚   â”œâ”€â”€ 03_drift_tests.ipynb\nâ”‚   â””â”€â”€ 04_shap_analysis.ipynb\nâ”‚\nâ”œâ”€â”€ outputs/                  # Generated reports and plots\nâ”œâ”€â”€ mlruns/                   # MLflow tracking logs\nâ”œâ”€â”€ requirements.txt          # Dependencies\nâ””â”€â”€ README.md\n```\n\n---\n\n## âš™ï¸ How to Use\n\n### ğŸ§  1. Install Requirements\n```bash\npip install -r requirements.txt\n```\n\n### ğŸ“Š 2. Run an Automated Experiment\n```bash\npython src/run_experiment.py --data data/KDDTest+.arff --model rf\n```\n\nThis will:\n1. Load and preprocess the dataset.\n2. Train a baseline model.\n3. Mutate the data (noise, drift, feature drop).\n4. Evaluate drift and robustness.\n5. Compute SHAP explainability.\n6. Generate and save experiment reports and plots in `outputs/`.\n\n### ğŸ–¥ï¸ 3. Launch Streamlit Dashboard\n```bash\nstreamlit run src/dashboard.py\n```\nExplore the full lab visually â€” upload data, mutate it, visualize SHAP, and generate reports.\n\n### ğŸ“ˆ 4. Visualize Saved Results\n```bash\npython src/visualize_results.py\n```\nDisplays saved performance charts, drift summaries, and SHAP plots.\n\n---\n\n## ğŸ§ª Supported Datasets\n- NSL-KDD (KDDTrain+, KDDTest+.arff)\n- CIC-IDS2017 *(planned Phase 2)*\n- UNSW-NB15 *(planned Phase 2)*\n\n---\n\n## ğŸ“˜ Roadmap\n**Phase 1 (âœ… Done):** Core pipeline, dashboards, and drift analysis.  \n**Phase 2 (ğŸš§ Next):** Modern IDS datasets (CIC-IDS2017, UNSW-NB15).  \n**Phase 3 (ğŸ”¬ Planned):** Adversarial sample generation (GAN/VAE).  \n**Phase 4 (â˜ï¸ Planned):** Real-time drift monitoring and deployment.\n\n---\n\n## ğŸ“„ License\nMIT â€” Free for education and research.\n\n---\n\n## âœ‰ï¸ Contact\nCreated by **Kapitan Lev âš“**  \nAI-powered Cyber Analyst & ML Researcher",
    "readme_checksum": "b1d4b19e647620f98c3e186c02eaf09c",
    "readme_loaded": true,
    "readme_last_updated": "2025-12-09T21:52:18.932591Z"
  }
}